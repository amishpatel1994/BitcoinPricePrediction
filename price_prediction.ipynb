{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers.core import Activation, Dense, Dropout\n",
    "from keras.layers.recurrent import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "\n",
    "The data from the csv is of an NxD matrix where N represents the number of examples and D is the number of features. This data will need to be normalized and split into windows of size 30 (represents the number of consecutive days) which results in a tensor. The dimensions are then N-w x d x D, where N is the number of examples, w is the window size, d is the number of days to examine in each sampled data, and D is the number of features.\n",
    "\n",
    "The normalization process is as follows for every feature. For each window, dividing each value by the first value in the window and then, subtract 1. \n",
    "\n",
    "After normalizing, the data is split into 90% training data and 10% test data. This is done such that 90% of the windows are used for training data and 10% of the windows are used for testing. We shuffle the windows but not the contents within the window, which ensures that the order of the consecutive days is maintained within the window. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Data with date:  (1818, 11)\n",
      "Shape of data without date:  (1818, 10)\n"
     ]
    }
   ],
   "source": [
    "window_size = 30\n",
    "file_name = \"blockchain_data.csv\"\n",
    "raw_data = pd.read_csv(file_name)\n",
    "print(\"Shape of Data with date: \", raw_data.shape)\n",
    "\n",
    "# Remove date column and change data types to float\n",
    "data = raw_data.drop('Date', 1)\n",
    "print(\"Shape of data without date: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1788, 30, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.values.tolist()\n",
    "tmp_arr = []\n",
    "for idx in range(len(data) - window_size):\n",
    "    tmp_arr.append(data[idx: idx + window_size])\n",
    "\n",
    "dataset = np.array(tmp_arr)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
