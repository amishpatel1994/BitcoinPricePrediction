{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers.core import Activation, Dense, Dropout\n",
    "from keras.layers.recurrent import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "\n",
    "The data from the csv is of an NxD matrix where N represents the number of examples and D is the number of features. This data will need to be normalized and split into windows of size 30 (represents the number of consecutive days) which results in a tensor. The dimensions are then N-w x d x D, where N is the number of examples, w is the window size, d is the number of days to examine in each sampled data, and D is the number of features.\n",
    "\n",
    "The normalization process is as follows for every feature. For each window, dividing each value by the first value in the window and then, subtract 1. \n",
    "\n",
    "After normalizing, the data is split into 90% training data and 10% test data. This is done such that 90% of the windows are used for training data and 10% of the windows are used for testing. We shuffle the windows but not the contents within the window, which ensures that the order of the consecutive days is maintained within the window. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Data with date:  (1818, 11)\n",
      "Shape of data without date:  (1818, 10)\n"
     ]
    }
   ],
   "source": [
    "window_size = 30\n",
    "file_name = \"blockchain_data.csv\"\n",
    "dropout = 0.2\n",
    "activation_function=\"linear\"\n",
    "loss_function=\"mse\"\n",
    "optimizer=\"adam\"\n",
    "batch_size=1024\n",
    "nb_epoch=50\n",
    "validation_split=0.05\n",
    "\n",
    "raw_dataset = pd.read_csv(file_name)\n",
    "print(\"Shape of Data with date: \", raw_dataset.shape)\n",
    "\n",
    "# Remove date column and change data types to float\n",
    "dataset = raw_dataset.drop('Date', 1)\n",
    "print(\"Shape of data without date: \", dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1788, 30, 10)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.values.tolist()\n",
    "tmp_arr = []\n",
    "for idx in range(len(dataset) - window_size):\n",
    "    tmp_arr.append(dataset[idx: idx + window_size])\n",
    "\n",
    "data = np.array(tmp_arr)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1788, 30, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 5.03526891e-03,  0.00000000e+00, -5.37740978e-02,\n",
       "         4.42871620e-02,  4.05405405e-02,  1.19726116e-01,\n",
       "        -1.03708813e-01, -1.34670718e-01, -6.73726840e-02,\n",
       "        -8.07617418e-02],\n",
       "       [-9.86339474e-03,  0.00000000e+00, -1.30137313e-01,\n",
       "        -6.01418068e-02, -5.40540541e-02, -1.25549454e-01,\n",
       "         1.36215627e-01,  4.38104636e-02,  7.47985663e-02,\n",
       "         2.13392749e-01],\n",
       "       [-4.10274140e-02,  0.00000000e+00, -2.36333955e-02,\n",
       "        -4.15726959e-02, -6.75675676e-03, -1.70761313e-01,\n",
       "         1.63654365e-01,  1.50475409e-01,  1.55791835e-01,\n",
       "         4.98619751e-01],\n",
       "       [-4.33078568e-02,  0.00000000e+00, -1.24267390e-01,\n",
       "        -7.93547396e-02, -4.05405405e-02, -1.87216289e-01,\n",
       "         1.80567168e-01,  8.13382457e-02,  1.32706337e-01,\n",
       "         1.93184492e-01],\n",
       "       [-7.05578946e-02,  5.95788830e-03,  3.66842511e-02,\n",
       "        -1.31881384e-01, -5.58959121e-02, -2.40374103e-01,\n",
       "         2.34583463e-01,  1.99768521e-01,  1.42823881e-01,\n",
       "         6.07240662e-01],\n",
       "       [-1.32822787e-01,  1.99080658e-02,  6.76261247e-02,\n",
       "        -2.17512118e-01, -9.03522657e-02, -2.85724901e-01,\n",
       "         2.28287111e-01,  2.43456789e-01,  9.54993156e-02,\n",
       "         7.45097252e-01],\n",
       "       [-1.44969280e-01,  1.99080658e-02, -2.81676640e-01,\n",
       "        -2.93935243e-03,  1.92189834e-01, -7.76349514e-02,\n",
       "        -7.52286849e-02, -8.15249970e-03,  8.09826859e-02,\n",
       "        -6.04072112e-02],\n",
       "       [-1.55787048e-01,  1.99080658e-02, -2.52590441e-01,\n",
       "        -2.54237881e-01, -9.72435364e-02, -2.09330599e-01,\n",
       "         6.56039154e-02, -1.22953806e-01, -5.67965344e-02,\n",
       "        -2.58080101e-01],\n",
       "       [-1.80100001e-01,  1.99080658e-02, -8.14530942e-02,\n",
       "        -3.01906733e-01, -1.38591161e-01, -2.91920055e-01,\n",
       "         1.67301000e-01,  7.81819188e-03, -1.41038847e-02,\n",
       "         4.03410631e-01],\n",
       "       [-1.57328228e-01,  1.99080658e-02,  7.04933184e-02,\n",
       "        -2.95932837e-01, -1.59264973e-01, -3.78853722e-01,\n",
       "         3.75061388e-01,  1.80203444e-01,  1.33496550e-01,\n",
       "         7.38468589e-01],\n",
       "       [-1.43973105e-01,  1.99080658e-02,  1.20776762e-02,\n",
       "        -1.90397216e-01, -4.21133707e-02, -2.77397199e-01,\n",
       "         1.92941830e-01,  1.47741001e-01,  1.20398070e-01,\n",
       "         4.76464870e-01],\n",
       "       [-1.12114478e-01,  1.99080658e-02, -2.54426445e-01,\n",
       "        -2.16926492e-02,  1.23277126e-01, -1.04333890e-01,\n",
       "        -8.24754156e-03,  8.48588529e-02,  9.22679103e-02,\n",
       "         1.41218694e-01],\n",
       "       [-1.02706286e-01,  1.99080658e-02, -9.90063127e-02,\n",
       "        -1.69886836e-01, -6.27871828e-02, -2.44079416e-01,\n",
       "         1.95044113e-01,  1.08707681e-01,  9.81486446e-02,\n",
       "         4.26153096e-01],\n",
       "       [-9.62429495e-02,  1.99080658e-02, -8.61639927e-02,\n",
       "        -2.26866824e-01, -1.31699890e-01, -2.10120035e-01,\n",
       "         1.49699605e-01,  2.28251547e-04, -2.12016877e-02,\n",
       "         1.87365646e-01],\n",
       "       [-1.31233116e-01,  1.99080658e-02, -2.56833162e-01,\n",
       "        -1.83891912e-01, -4.21133707e-02, -1.57600739e-01,\n",
       "         3.15175463e-02, -6.35254028e-02, -3.12098720e-02,\n",
       "        -4.46774508e-02],\n",
       "       [-1.37503768e-01,  1.99080658e-02, -1.29916602e-01,\n",
       "        -1.53318579e-01, -7.65746378e-04, -2.37419092e-01,\n",
       "         1.33255447e-01,  1.20071842e-01,  1.10284053e-01,\n",
       "         1.37691136e-01],\n",
       "       [-1.36637230e-01,  1.99080658e-02, -1.79189337e-01,\n",
       "        -7.78435111e-02,  8.88207729e-02, -2.23201979e-01,\n",
       "         1.11990673e-01,  1.44538563e-01,  1.87125178e-01,\n",
       "         1.10928850e-01],\n",
       "       [-1.39766802e-01,  1.99080658e-02, -2.02434128e-01,\n",
       "        -2.76467461e-02,  1.50842209e-01, -1.82792447e-01,\n",
       "         5.44765944e-02,  1.54763771e-01,  1.89848590e-01,\n",
       "         2.88320961e-01],\n",
       "       [-1.35821936e-01,  1.85492283e-02, -1.30463804e-01,\n",
       "        -1.52982322e-01, -8.19026761e-03, -2.29126565e-01,\n",
       "         1.21509890e-01,  8.42409599e-02,  9.87765815e-02,\n",
       "         1.34427989e-02],\n",
       "       [-1.26775605e-01,  1.23299338e-02, -9.59452364e-02,\n",
       "        -1.43280479e-01, -8.19026761e-03, -2.29983040e-01,\n",
       "         1.35617522e-01,  7.91594810e-02,  1.12598247e-01,\n",
       "         9.15503563e-02],\n",
       "       [-1.10908012e-01,  1.23299338e-02, -2.60941635e-01,\n",
       "        -7.16862998e-02,  6.02104036e-02, -7.75955610e-02,\n",
       "        -3.90442433e-02, -7.02115592e-02,  6.40636686e-03,\n",
       "        -2.12649476e-01],\n",
       "       [-1.15682827e-01,  1.23299338e-02, -2.87046641e-01,\n",
       "        -1.19663051e-01,  1.23299338e-02, -1.05093529e-01,\n",
       "        -1.62804973e-02, -1.29971964e-01, -1.62804973e-02,\n",
       "        -3.67581773e-01],\n",
       "       [-1.19030362e-01,  1.23299338e-02, -7.03969891e-02,\n",
       "        -1.19553724e-01,  1.23299338e-02, -2.04224275e-01,\n",
       "         1.06400017e-01,  1.02441139e-01,  1.06400017e-01,\n",
       "        -4.85172326e-02],\n",
       "       [-1.38306177e-01,  1.23299338e-02, -5.56220290e-02,\n",
       "        -1.38173297e-01,  1.23299338e-02, -2.36714245e-01,\n",
       "         1.29100992e-01,  1.13989745e-01,  1.29100992e-01,\n",
       "         1.25939432e-02],\n",
       "       [-1.48634808e-01,  1.23299338e-02,  2.04752578e-02,\n",
       "        -2.38787774e-01, -9.71111402e-02, -2.59121755e-01,\n",
       "         1.51984661e-01,  6.34308744e-02,  2.74457787e-02,\n",
       "         7.28585687e-02],\n",
       "       [-1.53284511e-01,  1.23299338e-02, -6.45034443e-02,\n",
       "        -2.38216538e-01, -9.02710730e-02, -3.07425602e-01,\n",
       "         2.23982424e-01,  7.29182998e-02,  9.99301508e-02,\n",
       "        -1.61124503e-02],\n",
       "       [-1.47055465e-01,  1.23299338e-02, -1.54561774e-01,\n",
       "        -1.24495671e-01,  3.96902022e-02, -2.31382209e-01,\n",
       "         1.09087965e-01,  1.06355999e-01,  1.39063316e-01,\n",
       "        -2.01542713e-02],\n",
       "       [-1.53902105e-01,  1.23299338e-02, -2.29300646e-01,\n",
       "        -1.40380918e-01,  3.28501351e-02, -1.69751881e-01,\n",
       "         1.48057405e-02, -4.64065368e-02,  3.53761271e-02,\n",
       "        -3.30057219e-01],\n",
       "       [-1.63123021e-01,  1.23299338e-02, -4.38528262e-02,\n",
       "        -2.98281698e-01, -1.51831677e-01, -2.44936499e-01,\n",
       "         1.09224253e-01, -1.34864386e-01, -7.06499499e-02,\n",
       "        -1.08381455e-01]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the data\n",
    "normalized_data = np.zeros_like(data)\n",
    "normalized_data[:,1:,:] = data[:,1:,:] / data[:, 0:1, :] - 1\n",
    "print(normalized_data.shape)\n",
    "normalized_data[-1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1609, 29, 10)\n",
      "(1609,)\n",
      "(179, 29, 10)\n",
      "(179,)\n",
      "(179,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "split_idx = round(0.9*normalized_data.shape[0])\n",
    "training_data = normalized_data[:int(split_idx), :]\n",
    "np.random.shuffle(training_data)\n",
    "\n",
    "X_train = training_data[:, :-1]\n",
    "Y_train = training_data[:, -1]\n",
    "Y_train = Y_train[:, 0]\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "X_test = normalized_data[int(split_idx):, :-1]\n",
    "Y_test = normalized_data[int(split_idx):, -1, :]\n",
    "Y_test = Y_test[:, 0]\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "Y_daybefore = normalized_data[int(split_idx):, -2, :]\n",
    "Y_daybefore = Y_daybefore[:, 0]\n",
    "print(Y_daybefore.shape)\n",
    "\n",
    "# this is because the last window is used as the target\n",
    "sequence_length = window_size\n",
    "window_size = window_size - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "\n",
    "# First layer\n",
    "model.add(Bidirectional(LSTM(window_size, return_sequences=True), input_shape=(window_size, X_train.shape[-1]),))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "# Second layer\n",
    "model.add(Bidirectional(LSTM(window_size*2, return_sequences=True)))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "# Third layer\n",
    "model.add(Bidirectional(LSTM(window_size, return_sequences=False)))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(units=1))\n",
    "model.add(Activation(activation_function))\n",
    "\n",
    "model.compile(loss=loss_function, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1528 samples, validate on 81 samples\n",
      "Epoch 1/50\n",
      "1528/1528 [==============================] - 5s 4ms/step - loss: 0.0758 - val_loss: 0.0490\n",
      "Epoch 2/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0376 - val_loss: 0.0356\n",
      "Epoch 3/50\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 0.0282 - val_loss: 0.0271\n",
      "Epoch 4/50\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 0.0214 - val_loss: 0.0224\n",
      "Epoch 5/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0186 - val_loss: 0.0216\n",
      "Epoch 6/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0178 - val_loss: 0.0186\n",
      "Epoch 7/50\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 0.0145 - val_loss: 0.0164\n",
      "Epoch 8/50\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 9/50\n",
      "1528/1528 [==============================] - 2s 2ms/step - loss: 0.0118 - val_loss: 0.0146\n",
      "Epoch 10/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0110 - val_loss: 0.0137\n",
      "Epoch 11/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0097 - val_loss: 0.0131\n",
      "Epoch 12/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0093 - val_loss: 0.0122\n",
      "Epoch 13/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0086 - val_loss: 0.0112\n",
      "Epoch 14/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 15/50\n",
      "1528/1528 [==============================] - 2s 2ms/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 16/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 17/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0073 - val_loss: 0.0098\n",
      "Epoch 18/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0070 - val_loss: 0.0095\n",
      "Epoch 19/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0067 - val_loss: 0.0090\n",
      "Epoch 20/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0065 - val_loss: 0.0087\n",
      "Epoch 21/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0063 - val_loss: 0.0085\n",
      "Epoch 22/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0059 - val_loss: 0.0084\n",
      "Epoch 23/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0059 - val_loss: 0.0083\n",
      "Epoch 24/50\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 0.0059 - val_loss: 0.0082\n",
      "Epoch 25/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0055 - val_loss: 0.0081\n",
      "Epoch 26/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0055 - val_loss: 0.0082\n",
      "Epoch 27/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0055 - val_loss: 0.0082\n",
      "Epoch 28/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0052 - val_loss: 0.0079\n",
      "Epoch 29/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0053 - val_loss: 0.0077\n",
      "Epoch 30/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0052 - val_loss: 0.0076\n",
      "Epoch 31/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0049 - val_loss: 0.0077\n",
      "Epoch 32/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0050 - val_loss: 0.0076\n",
      "Epoch 33/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0047 - val_loss: 0.0076\n",
      "Epoch 34/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0048 - val_loss: 0.0077\n",
      "Epoch 35/50\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 0.0047 - val_loss: 0.0077\n",
      "Epoch 36/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0046 - val_loss: 0.0074\n",
      "Epoch 37/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0046 - val_loss: 0.0074\n",
      "Epoch 38/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0045 - val_loss: 0.0074\n",
      "Epoch 39/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0047 - val_loss: 0.0076\n",
      "Epoch 40/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0044 - val_loss: 0.0076\n",
      "Epoch 41/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0045 - val_loss: 0.0076\n",
      "Epoch 42/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0044 - val_loss: 0.0076\n",
      "Epoch 43/50\n",
      "1528/1528 [==============================] - 2s 991us/step - loss: 0.0044 - val_loss: 0.0076\n",
      "Epoch 44/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0041 - val_loss: 0.0074\n",
      "Epoch 45/50\n",
      "1528/1528 [==============================] - 2s 990us/step - loss: 0.0043 - val_loss: 0.0074\n",
      "Epoch 46/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0042 - val_loss: 0.0076\n",
      "Epoch 47/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0041 - val_loss: 0.0077\n",
      "Epoch 48/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0041 - val_loss: 0.0076\n",
      "Epoch 49/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0041 - val_loss: 0.0075\n",
      "Epoch 50/50\n",
      "1528/1528 [==============================] - 2s 1ms/step - loss: 0.0040 - val_loss: 0.0074\n",
      "Training time 107 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, validation_split=validation_split)\n",
    "training_time = int(math.floor(time.time() - start))\n",
    "print(\"Training time\", training_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of samples, -179, must be non-negative.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-8e92ba990b27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mthen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreal_y_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mdays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Bitcoin Price over last 6 months\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_major_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDateFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/matplotlib/dates.py\u001b[0m in \u001b[0;36mdrange\u001b[0;34m(dstart, dend, delta)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0mf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate2num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdinterval_end\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# new float-endpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;31m## date tickers and formatters ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/numpy/core/function_base.py\u001b[0m in \u001b[0;36mlinspace\u001b[0;34m(start, stop, num, endpoint, retstep, dtype, axis)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_index_deprecate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of samples, %s, must be non-negative.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0mdiv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mendpoint\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of samples, -179, must be non-negative."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test the model\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "#Create empty 2D arrays to store unnormalized values\n",
    "real_y_test = np.zeros_like(Y_test)\n",
    "real_y_predict = np.zeros_like(y_predict)\n",
    "unnormalized_bases = data[split_idx:,0:1,0]\n",
    "\n",
    "\n",
    "#Fill the 2D arrays with the real value and the predicted value by reversing the normalization process\n",
    "for i in range(Y_test.shape[0]):\n",
    "    y = Y_test[i]\n",
    "    predict = y_predict[i]\n",
    "    real_y_test[i] = (y+1)*unnormalized_bases[i]\n",
    "    real_y_predict[i] = (predict+1)*unnormalized_bases[i]\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "#Plot of the predicted prices versus the real prices\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(111)\n",
    "now = dt.datetime.now()\n",
    "then = now - dt.timedelta(days=real_y_predict.shape[0])\n",
    "days = mdates.drange(then,dt.timedelta(days=1))\n",
    "ax.set_title(\"Bitcoin Price over last 6 months\")\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval=30))\n",
    "plt.plot(days, real_y_predict, color = 'green', label = 'Predicted Price')\n",
    "plt.plot(days, real_y_test, color = 'red', label = 'Actual Price')\n",
    "ax.set_ylabel(\"Price (USD)\")\n",
    "ax.set_xlabel(\"Time (Days)\")\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
